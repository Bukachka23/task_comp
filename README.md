# Web Scraping Interface with Streamlit

This project provides a user-friendly web interface for scraping data from websites, displaying the scraped data, and allowing users to download it in JSON or CSV formats. Additionally, users can upload the scraped data directly to a Google Spreadsheet. Built with Streamlit, the application simplifies the process of web scraping, data visualization, and data export for users without deep technical knowledge.

## Demo deployed version

## Features

- **Web Scraping**: Scrape data from specified URLs.
- **Data Display**: Show scraped data directly in the web interface.
- **Data Download**: Download the scraped data as JSON or CSV files.
- **Google Spreadsheet Integration**: Upload scraped data to a Google Spreadsheet.

## Getting Started
https://taskcomp-2tqvpy8sfkixdeyuqyjyim.streamlit.app/

### Prerequisites

Before you begin, ensure you have the following installed:
- Python 3.8 or later
- pip

### Installation

1. Clone the repository:


2. Install the required Python packages:


### Usage

1. Start the Streamlit application:

2. Open your web browser and go to the address shown in your terminal (usually `http://localhost:8501`).

3. Enter the URL you wish to scrape and the path to your Google credentials file in the provided text input fields.

4. Click the `Scrape Data` button to scrape the data from the specified URL.

5. Use the `Show scraped data` checkbox to display the scraped data within the application.

6. Click the `Save Data to JSON` or `Save Data to CSV` buttons to download the data in the selected format.

7. To upload the data to a Google Spreadsheet, click the `Upload Data to Google Spreadsheet` button and enter the name of the spreadsheet.

## Contributing

Contributions are welcome! Please feel free to submit a pull request or open an issue for any bugs, feature requests, or improvements.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
# TASK_GS
# TASK_GS
# task_comp
